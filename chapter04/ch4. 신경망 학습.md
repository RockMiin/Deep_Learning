## ch4. 신경망 학습

**학습** : 훈련 데이터로부터 가중치 매개변수의 최적값을 자동으로 획득하는 것

**신경망이 학습할 수 있도록 해주는 지표인 손실 함수를 소개**하는 것이 이번 장의 목표 / 손실 함수의 값을 가급적 작게 만드는 기법으로, 함수의 기울기를 활용하는 경사법을 소개

기계학습은 데이터가 생명이다. 데이터에서 답을 찾고 데이터에서 패턴을 발견하고 데이터로 이야기를 만드는 것이 기계학습이다. 

보통 어떤 문제를 해결하려 들 때, 특히 어떤 패턴을 찾아내야 할 때는 사람이 이것저것 생각을 하고 답을 찾는 것이 일반적이다. 사람의 경험과 직관을 단서로 시행착오를 거듭하며 일을 진행 

**하지만** 기계학습에서는 사람의 개입을 최소화하고 수집한 데이터로부터 패턴을 찾으려 시도 특히 **신경망과 딥러닝은 기존 기계학습에서 사용하던 방법보다 사람의 개입을 더욱 배제할 수 있게 해주는 중요한 특성**을 지님 

주어진 데이터를 잘 활용하여 문제를 해결 -> 이미지에서 특징을 추출하고 그 특징의 패턴을 기계학습 기술로 학습하는 방법

특징 : 입력 데이터에서 본질적인 데이터를 정확하게 추출할 수 있도록 설계된 변환기

이미지의 특징을 보통 벡터로 기술 but 이미지를 벡터로 변환할 때 사용하는 특징은 사람이 설계 -> **특징을 제대로 설계하지 않으면 좋은 결과를 얻을 수 없다.**

ML은 사람이 생각한 특징을 가지고 기계 학습을 하여 결과를 도출하지만 신경망은 모든 문제를 주어진 데이터 그대로 입력 데이터로 활용해 학습

train, test 데이터를 나누는 이유는 우리가 원하는 것은 범용적으로 사용할 수 있는 모델이기 때문 (아직 보지 못한 데이터로도 문제를 올바르게 풀어내는 능력) -> 이러한 범용 능력을 획득하는 것이 **기계학습의 최종 목표**



**손실 함수**

​	신경망에서는 성능을 나타내는 지표

​	주로 평균 제곱 오차, 교차 엔트로피 오차를 사용

​	두 손실 함수 모두 정답은 원-핫 인코딩으로 구성되어 있기 때문에 교차 엔트로피를 구할 때는 정	답이 1일 때의 로그를 계산하면 된다.

**미니 배치**

데이터의 수가 많아져 모든 데이터를 대상으로 손실 함수 값을 구하려면 시간이 오래 걸림 -> 일일이 손실 함수를 계산할 수 없음 -> train set에서 일부만 골라서 학습을 수행 (무작위로 고름)



**왜 손실 함수를 사용하는가 ?**

​	정확도라는 지표를 놔두고 왜 굳이 손실 함수를 사용해야 하는가 ? -> 신경망 학습에서의 '미분'의 	역할에 주목하면 해결이 된다. 

​	신경망 학습에서는 최적의 매개변수를 탐색할 때 손실 함수의 값을 가능한 작게 하는 매개변수 값	을 찾는다. 이때 매개변수의 미분(기울기)을 계산하고, 그 미분 값을 단서로 매개변수 값을 서서히 	갱신하는 과정을 반복한다 . 가령 여기에 가상의 신경망이 있고 그 신경망의 어느 한 가중치 매개 변수에 주목을 한다고 하자. 이때 그 가중치 매개변수의 손실 함수의 미분이랑 가중치 매개변수의 값을 아주 조금 변화시켰을 때 손실함수가 어떻게 변하냐의 의미이다. 만약 이 미분값이 음수면 양의 방향으로 변화, 미분 값이 양수면 음의 방향으로 변화, 0이면 갱신을 멈춤

정확도를 지표로 삼아서는 안 되는 이유는 미분 값이 대부분의 장소에서 0이 되어 매개 변수를 갱신할 수 없기 때문 -> 0이 되는 이유는 ? -> 예로 한 신경망이 100장의 train set 중 32장을 올바르게 인식한다고 가정 -> 정확도는 32% -> 가중치 매개변수의 값을 조금 바꾼다고 해도 정확도는 32%일 것이다. -> 매개변수를 약간만 조정해서는 정확도가 개선되지 않고 ㅇ일정하게 유지 / 만약 개선된다 하더라도 32.012과 같은 연속적인 변화가 아니라 33%나 34%처럼 불연속적으로 변화하기 때문에 안됨 but 손실 함수는 조금만 매개변수 값을 변화해도 손실 함수의 값도 연속적으로 변화함

즉 정확도는 매개변수의 미세한 변화에는 거의 반응을 보이지 않고, 반응이 있더라도 그 값이 불연속적으로 갑자기 변화한다. -> 이는 계단 함수를 활성화 함수로 사용하지 않는 이유와도 같다 



미분 : 한 순간의 변화량

전방 차분((x+h)-x )의 문제점을 개선한 중심 차분을 사용

전방 차분의 문제점 : 1. 컴퓨터는 반올림 오차를 하여 h값을 10^-4 정도로 사용하는 것이 best

2. h를 무한히 좁히는 것이 불가능하기 때문에 미분 값이 정확하게 일치하지는 않음



**기울기가 가리키는 쪽이 각 장소에서 함수의 출력 값을 가장 크게 줄이는 방향**



일반적인 문제의 손실함수는 매우 복잡 -> 매개변수 공간이 광대하여 어디가 최솟값이 되는 곳인지 알아내기가 어렵다. -> 기울기를 잘 이용해 함수의 최솟값을 찾으려는 것이 경사법 -> 기울기가 가리키는 곳에 정말 함수의 최솟값이 있는지, 그쪽이 나아갈 방향인지 보장은 할 수 없다. 기울기가 가리키는 방향에 최솟값이 없는 경우도 대부분임/ 경사법은 기울기가 0인 장소를 찾지만 그것이 반드시 최솟값이라고는 할 수 없다. 극솟값이나 안정점일 가능성도 있음 / 지역 최소 값에 빠질 수도 있다

**경사법**

​	현 위치에서 기울어진 방향으로 일정 거리만큼 이동을 반복해서 함수의 값을 점차 줄이는 법

​	일반적으로 신경망 분야에서의 경사법은 '경사 하강법'을 사용

​	학습률 : 한 번의 학습으로 얼마나 매개변수 값을 갱신하느냐를 결정

​	학습률이 너무 크면 큰 값으로 발산해버리고, 너무 작으면 거의 갱신이 되지 않음 -> 적절하게 설정

​	**손실 함수의 변화량이 가중치의  형상과 같다는 것이 핵심**



**학습 알고리즘 구현하기**

전제 : 신경망에는 적응 가능한 가중치와 편향이 있고, 이 가중치와 편향을 훈련 데이터에 적응하도록 조정하는 과정을 학습이라 한다. 신경망 학습은 다음과 같이 4단계로 수행한다.

1. 미니 배치

   훈련 데이터 중 일부를  무작위로 가져온다. 이렇게 선별한 데이터를 미니배치라 하며 이 미니배치의 손실 함수 값을 줄이는 것이 목표

2.  기울기 산출

   미니 배치의 손실 함수 값을 줄이기 위해 각 가중치 매개변수의 기울기를 구한다. 기울기는 손실 함수의 값을 가장 작게 하는 방향을 제시한다

3. 매개변수 갱신

   가중치 매개변수를 기울기 방향으로 아주 조금 갱신

4. 반복

   1-3단계를 반복한다.



가중치 매개변수의 초값을 무엇으로 설정하냐가 신경망 학습의 성공을 좌우하기도 한다

이번 장에서는 수치 미분 방식으로 매개변수의 기울기를 계산하는데 이 계산을 고속으로 수행하는 오차역전파법을 다음 장에서 배울 계획



이게 결국에 모델을 만들 때 입력값 x로부터 y값을 도출한 다음에 정답 레이블 t를 이용해서 손실 함수 값을 구함. 손실 함수 값을 구한 다음에 그때의 변화량을 구함 그래서 양수면 음의 방향으로, 음수면 양의 방향으로 가중치 매개변수 값을 변경 그렇게 모델의 성능을 개선시킴 -> 그런데 변화량이 0일 때가 최선은 아닐 수가 있음



​	



